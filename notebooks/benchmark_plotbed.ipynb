{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRPT vs. BASRPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['benchmark_data', 'benchmarks', 'envs', 'config'])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import trafpy\n",
    "import trafpy.generator as tpg\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_to_benchmark_data = os.path.dirname(trafpy.__file__)+'/../data/testbed_data/ndf50_1s_university_testbed_data_v3.obj'\n",
    "filehandler = open(path_to_benchmark_data, 'rb')\n",
    "tb_dict = pickle.load(filehandler)\n",
    "\n",
    "print(tb_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<trafpy.manager.src.simulators.dcn.DCN object at 0x7ff1085b07c0>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff017992880>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff0143e4820>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff01310a6d0>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff011d71b20>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff01037dca0>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff00d617940>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff00b3a6580>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff00927b640>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff0073680d0>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff0040c8bb0>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff001883820>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7ff00df01190>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7feff9868190>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7feff70e2550>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7feff4e47550>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7feff248cd00>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7fefefcb4850>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7fefed341c10>, <trafpy.manager.src.simulators.dcn.DCN object at 0x7fefea22ee80>]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "envs = tb_dict['envs']\n",
    "print(envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "### Key Stats to Compare\n",
    "- Average flow completion time\n",
    "- 99th percentile flow completion time\n",
    "- Queue length\n",
    "- Throughput\n",
    "\n",
    "### Key Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 8396000.0 time units\n",
      "Total number of generated demands (jobs or flows): 3000\n",
      "Total info arrived: 9692671.0 info units\n",
      "Load: 1.162527826431793 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 9692671.0 info units\n",
      "Throughput: 1.1544391376846117 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 3000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 8337581.9310495285 time units\n",
      "Time first flow completed: 3000.0 time units\n",
      "Time last flow completed: 8396000.0 time units\n",
      "Total number of demands that arrived and became flows: 3000\n",
      "Total number of flows that were completed: 3000\n",
      "Total number of dropped flows: 0\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 73016.42353017052 time units\n",
      "99th percentile FCT: 652356.6822973932 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 4415000.0 time units\n",
      "Total number of generated demands (jobs or flows): 3000\n",
      "Total info arrived: 10155019.0 info units\n",
      "Load: 2.396666342080379 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 10155019.0 info units\n",
      "Throughput: 2.3001175537938843 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 3000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4237143.411120438 time units\n",
      "Time first flow completed: 19000.0 time units\n",
      "Time last flow completed: 4415000.0 time units\n",
      "Total number of demands that arrived and became flows: 3000\n",
      "Total number of flows that were completed: 3000\n",
      "Total number of dropped flows: 0\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 139054.59359531172 time units\n",
      "99th percentile FCT: 1408356.9303191176 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_srpt'\n",
      "Total session duration: 9012000.0 time units\n",
      "Total number of generated demands (jobs or flows): 3000\n",
      "Total info arrived: 9692671.0 info units\n",
      "Load: 1.162527826431793 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 9672848.0 info units\n",
      "Throughput: 1.073329782512206 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 3000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 8337581.9310495285 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 9012000.0 time units\n",
      "Total number of demands that arrived and became flows: 3000\n",
      "Total number of flows that were completed: 2997\n",
      "Total number of dropped flows: 3\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 93784.96804812863 time units\n",
      "99th percentile FCT: 2914011.9805507576 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_srpt'\n",
      "Total session duration: 5509000.0 time units\n",
      "Total number of generated demands (jobs or flows): 3000\n",
      "Total info arrived: 10155019.0 info units\n",
      "Load: 2.396666342080379 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 9768126.0 info units\n",
      "Throughput: 1.773121437647486 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 3000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4237143.411120438 time units\n",
      "Time first flow completed: 3000.0 time units\n",
      "Time last flow completed: 5509000.0 time units\n",
      "Total number of demands that arrived and became flows: 3000\n",
      "Total number of flows that were completed: 2894\n",
      "Total number of dropped flows: 106\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 189700.2499562553 time units\n",
      "99th percentile FCT: 3628180.1146220015 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.5_repeat_0_scheduler_srpt'\n",
      "Total session duration: 5337000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 19505816.0 info units\n",
      "Load: 5.953533458171324 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 12039275.0 info units\n",
      "Throughput: 2.2558131909312347 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3276342.7193355137 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 5337000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 3806\n",
      "Total number of dropped flows: 2194\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 337701.44527530094 time units\n",
      "99th percentile FCT: 4047710.5993050216 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.4_repeat_0_scheduler_srpt'\n",
      "Total session duration: 6299000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 19571726.0 info units\n",
      "Load: 4.79361625559097 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 14069029.0 info units\n",
      "Throughput: 2.2335337355135736 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4082872.920245291 time units\n",
      "Time first flow completed: 2000.0 time units\n",
      "Time last flow completed: 6299000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 4336\n",
      "Total number of dropped flows: 1664\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 320990.83098180365 time units\n",
      "99th percentile FCT: 4703755.100952881 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.3_repeat_0_scheduler_srpt'\n",
      "Total session duration: 7704000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 20203364.0 info units\n",
      "Load: 3.575173859014589 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 16317959.0 info units\n",
      "Throughput: 2.1181151349948077 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 5651015.809778988 time units\n",
      "Time first flow completed: 2000.0 time units\n",
      "Time last flow completed: 7704000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 4906\n",
      "Total number of dropped flows: 1094\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 299321.1735393999 time units\n",
      "99th percentile FCT: 5639962.029500319 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.5_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 4047000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 19505816.0 info units\n",
      "Load: 5.953533458171324 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 10957055.0 info units\n",
      "Throughput: 2.707451198418582 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3276342.7193355137 time units\n",
      "Time first flow completed: 9000.0 time units\n",
      "Time last flow completed: 4047000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 3236\n",
      "Total number of dropped flows: 2764\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 460247.2404157312 time units\n",
      "99th percentile FCT: 3732565.8332030145 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_1.0_repeat_0_scheduler_srpt'\n",
      "Total session duration: 5469000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 39768948.0 info units\n",
      "Load: 11.917002073972085 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 13210395.0 info units\n",
      "Throughput: 2.4155046626439933 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3337160.4496788103 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 5469000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 4127\n",
      "Total number of dropped flows: 7873\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 432518.4933358878 time units\n",
      "99th percentile FCT: 4314237.221444194 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.4_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 5003000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 19571726.0 info units\n",
      "Load: 4.79361625559097 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 12891298.0 info units\n",
      "Throughput: 2.5767135718568857 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4082872.920245291 time units\n",
      "Time first flow completed: 16000.0 time units\n",
      "Time last flow completed: 5003000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 3827\n",
      "Total number of dropped flows: 2173\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 458717.18233089417 time units\n",
      "99th percentile FCT: 4415959.126593551 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_1.0_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 4049000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 39768948.0 info units\n",
      "Load: 11.917002073972085 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 10771487.0 info units\n",
      "Throughput: 2.6602832798221785 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3337160.4496788103 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 4049000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 3072\n",
      "Total number of dropped flows: 8928\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 570924.6910977524 time units\n",
      "99th percentile FCT: 3876233.9558817875 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.9_repeat_0_scheduler_srpt'\n",
      "Total session duration: 5812000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 38257272.0 info units\n",
      "Load: 10.723764189172792 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 13381468.0 info units\n",
      "Throughput: 2.302386097728837 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3567522.683744418 time units\n",
      "Time first flow completed: 2000.0 time units\n",
      "Time last flow completed: 5812000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 4378\n",
      "Total number of dropped flows: 7622\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 424546.7962998527 time units\n",
      "99th percentile FCT: 4394403.862356167 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.3_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 6644000.0 time units\n",
      "Total number of generated demands (jobs or flows): 6000\n",
      "Total info arrived: 20203364.0 info units\n",
      "Load: 3.575173859014589 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 17850810.0 info units\n",
      "Throughput: 2.6867564720048165 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 6000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 5651015.809778988 time units\n",
      "Time first flow completed: 9000.0 time units\n",
      "Time last flow completed: 6644000.0 time units\n",
      "Total number of demands that arrived and became flows: 6000\n",
      "Total number of flows that were completed: 5273\n",
      "Total number of dropped flows: 727\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 341392.09748175176 time units\n",
      "99th percentile FCT: 5038014.983243028 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.9_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 4314000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 38257272.0 info units\n",
      "Load: 10.723764189172792 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 12100978.0 info units\n",
      "Throughput: 2.8050482151135836 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 3567522.683744418 time units\n",
      "Time first flow completed: 3000.0 time units\n",
      "Time last flow completed: 4314000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 3580\n",
      "Total number of dropped flows: 8420\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 523956.2334693389 time units\n",
      "99th percentile FCT: 4120273.8300301693 time units\n",
      "None\n",
      "Net capacity: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.8_repeat_0_scheduler_srpt'\n",
      "Total session duration: 6172000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 39169264.0 info units\n",
      "Load: 9.560761887833216 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 14970786.0 info units\n",
      "Throughput: 2.425597213220998 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4096876.845123171 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 6172000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 4680\n",
      "Total number of dropped flows: 7320\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 425050.74306698545 time units\n",
      "99th percentile FCT: 4880500.336862084 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.8_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 4833000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 39169264.0 info units\n",
      "Load: 9.560761887833216 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 12362303.0 info units\n",
      "Throughput: 2.557894268570246 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4096876.845123171 time units\n",
      "Time first flow completed: 5000.0 time units\n",
      "Time last flow completed: 4833000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 3534\n",
      "Total number of dropped flows: 8466\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 601853.9269736807 time units\n",
      "99th percentile FCT: 4648849.103770076 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.7_repeat_0_scheduler_srpt'\n",
      "Total session duration: 7392000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 40410324.0 info units\n",
      "Load: 8.328396047217856 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 17093092.0 info units\n",
      "Throughput: 2.3123771645021645 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4852113.632792388 time units\n",
      "Time first flow completed: 1000.0 time units\n",
      "Time last flow completed: 7392000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 5205\n",
      "Total number of dropped flows: 6795\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 444703.8913789788 time units\n",
      "99th percentile FCT: 5811604.711163894 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.6_repeat_0_scheduler_srpt'\n",
      "Total session duration: 7623000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 40501500.0 info units\n",
      "Load: 7.187844980596919 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 18548272.0 info units\n",
      "Throughput: 2.433198478289387 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 5634720.852958146 time units\n",
      "Time first flow completed: 4000.0 time units\n",
      "Time last flow completed: 7623000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 5672\n",
      "Total number of dropped flows: 6328\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 420883.23336154997 time units\n",
      "99th percentile FCT: 5951309.504442927 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.7_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 5718000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 40410324.0 info units\n",
      "Load: 8.328396047217856 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 14956065.0 info units\n",
      "Throughput: 2.6156112277019936 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 4852113.632792388 time units\n",
      "Time first flow completed: 4000.0 time units\n",
      "Time last flow completed: 5718000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 4173\n",
      "Total number of dropped flows: 7827\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 592792.9449787718 time units\n",
      "99th percentile FCT: 5453430.690742234 time units\n",
      "None\n",
      "Net capacity: 12\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Simulation name: 'benchmark_university_load_0.6_repeat_0_scheduler_basrpt'\n",
      "Total session duration: 6422000.0 time units\n",
      "Total number of generated demands (jobs or flows): 12000\n",
      "Total info arrived: 40501500.0 info units\n",
      "Load: 7.187844980596919 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 15698288.0 info units\n",
      "Throughput: 2.4444546870133914 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 12000\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 5634720.852958146 time units\n",
      "Time first flow completed: 5000.0 time units\n",
      "Time last flow completed: 6422000.0 time units\n",
      "Total number of demands that arrived and became flows: 12000\n",
      "Total number of flows that were completed: 4347\n",
      "Total number of dropped flows: 7653\n",
      "Total number of flows in queues at end of session: 0\n",
      "Average FCT: 644911.443312581 time units\n",
      "99th percentile FCT: 6131803.386092689 time units\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "for env in envs:\n",
    "    print('Net capacity: {}'.format(env.network.graph['max_nw_capacity']))\n",
    "    print(env.get_scheduling_session_summary(print_summary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# collect testbed stats into dict\n",
    "testbed_stats = {'test_{}'.format(i): \n",
    "                 {envs[i].scheduler.scheduler_name: \n",
    "                  {'load_rate': envs[i].load, \n",
    "                   'load_frac': envs[i].load/envs[i].network.graph['max_nw_capacity'],\n",
    "                   'avrg_fct': envs[i].avrg_fct,\n",
    "                   'nn_fct': envs[i].nn_fct,\n",
    "                   'q_dict': envs[i].queue_evolution_dict,\n",
    "                   'throughput': envs[i].throughput}\n",
    "                 } for i in range(len(envs))}\n",
    "\n",
    "# find classes\n",
    "classes = []\n",
    "for test in testbed_stats.keys():\n",
    "    for _class in testbed_stats[test].keys():\n",
    "        if _class not in classes:\n",
    "            classes.append(_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# avrg fct\n",
    "plot_dict = {_class: {'x_values': [], 'y_values': []} for _class in classes}\n",
    "\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    plot_dict[_class]['x_values'].append(testbed_stats[test][_class]['load_frac'])\n",
    "    plot_dict[_class]['y_values'].append(testbed_stats[test][_class]['avrg_fct'])\n",
    "\n",
    "fig = tpg.plot_val_scatter(plot_dict=plot_dict,xlabel='Load', ylabel='Average FCT (us)', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# 99th percentile fct\n",
    "plot_dict = {_class: {'x_values': [], 'y_values': []} for _class in classes}\n",
    "\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    plot_dict[_class]['x_values'].append(testbed_stats[test][_class]['load_frac'])\n",
    "    plot_dict[_class]['y_values'].append(testbed_stats[test][_class]['nn_fct'])\n",
    "\n",
    "fig = tpg.plot_val_scatter(plot_dict=plot_dict,xlabel='Load', ylabel='99th Percentile FCT (us)', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy\n",
    "\n",
    "# queue length\n",
    "plot_dict = {}\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    load = testbed_stats[test][_class]['load_frac']\n",
    "    try:\n",
    "        plot_dict[load][_class]['x_values'] = None\n",
    "        plot_dict[load][_class]['y_values'] = None\n",
    "    except KeyError:\n",
    "        # not yet added this load\n",
    "        try:\n",
    "            plot_dict[load][_class] = {}\n",
    "            plot_dict[load][_class]['x_values'] = None\n",
    "            plot_dict[load][_class]['y_values'] = None\n",
    "        except KeyError:\n",
    "            plot_dict[load] = {}\n",
    "            plot_dict[load][_class] = {}\n",
    "            plot_dict[load][_class]['x_values'] = None\n",
    "            plot_dict[load][_class]['y_values'] = None\n",
    "\n",
    "src = 'server_2'\n",
    "dst='server_10'\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    load = testbed_stats[test][_class]['load_frac']\n",
    "    plot_dict[load][_class]['x_values'] = testbed_stats[test][_class]['q_dict'][src][dst]['times'] \n",
    "    plot_dict[load][_class]['y_values'] = testbed_stats[test][_class]['q_dict'][src][dst]['queue_lengths']\n",
    "    \n",
    "for load in plot_dict.keys():\n",
    "    tpg.plot_val_line(plot_dict=plot_dict[load],xlabel='Time (us)', ylabel='{}-{} Queue Length (Bytes)'.format(src,dst), show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# throughput\n",
    "plot_dict = {}\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    load = testbed_stats[test][_class]['load_frac']\n",
    "    try:\n",
    "        plot_dict[load]['x_values'].append(_class[0])\n",
    "        plot_dict[load]['y_values'].append(testbed_stats[test][_class]['throughput'])\n",
    "    except KeyError:\n",
    "        try:\n",
    "            plot_dict[load] = {}\n",
    "            plot_dict[load]['x_values'].append(_class[0])\n",
    "            plot_dict[load]['y_values'].append(testbed_stats[test][_class]['throughput'])\n",
    "        except KeyError:\n",
    "            plot_dict[load] = {}\n",
    "            plot_dict[load]['x_values'] = []\n",
    "            plot_dict[load]['y_values'] = []\n",
    "            plot_dict[load]['x_values'].append(_class[0])\n",
    "            plot_dict[load]['y_values'].append(testbed_stats[test][_class]['throughput'])\n",
    "    \n",
    "print(plot_dict)\n",
    "for load in plot_dict.keys():\n",
    "    tpg.plot_val_bar(x_values=plot_dict[load]['x_values'],y_values=plot_dict[load]['y_values'],xlabel='Scheduler', ylabel='Load {} Throughput (B/s)'.format(str(round(load,2))), show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning BASRPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import trafpy\n",
    "import trafpy.generator as tpg\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_to_benchmark_data = os.path.dirname(trafpy.__file__)+'/../data/testbed_data/ndf10_university_testbed_data_basrpt_tuning.obj'\n",
    "filehandler = open(path_to_benchmark_data, 'rb')\n",
    "tb_dict = pickle.load(filehandler)\n",
    "\n",
    "print(tb_dict.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = tb_dict['envs']\n",
    "print(envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "### Key Stats to Compare\n",
    "- Throughput vs. V\n",
    "- Average FCT vs. V\n",
    "- 99th Percentile vs. V\n",
    "- Queue Evolution (V composite)\n",
    "\n",
    "### Key Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in envs:\n",
    "    print('Net capacity: {}'.format(env.network.graph['max_nw_capacity']))\n",
    "    print(env.get_scheduling_session_summary(print_summary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect testbed stats into dict\n",
    "testbed_stats = {'test_{}'.format(i): \n",
    "                 {envs[i].scheduler.scheduler_name: \n",
    "                  {'load_rate': envs[i].load, \n",
    "                   'load_frac': envs[i].load/envs[i].network.graph['max_nw_capacity'],\n",
    "                   'avrg_fct': envs[i].avrg_fct,\n",
    "                   'nn_fct': envs[i].nn_fct,\n",
    "                   'q_dict': envs[i].queue_evolution_dict,\n",
    "                   'throughput': envs[i].throughput,\n",
    "                   'V': envs[i].scheduler.V}\n",
    "                 } for i in range(len(envs))}\n",
    "\n",
    "# find classes\n",
    "classes = []\n",
    "for test in testbed_stats.keys():\n",
    "    for _class in testbed_stats[test].keys():\n",
    "        if _class not in classes:\n",
    "            classes.append(_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avrg fct\n",
    "plot_dict = {_class: {'x_values': [], 'y_values': []} for _class in classes}\n",
    "\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    plot_dict[_class]['x_values'].append(testbed_stats[test][_class]['V'])\n",
    "    plot_dict[_class]['y_values'].append(testbed_stats[test][_class]['avrg_fct'])\n",
    "\n",
    "fig = tpg.plot_val_scatter(plot_dict=plot_dict,xlabel='V', ylabel='Average FCT (us)', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 99th percentile fct\n",
    "plot_dict = {_class: {'x_values': [], 'y_values': []} for _class in classes}\n",
    "\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    plot_dict[_class]['x_values'].append(testbed_stats[test][_class]['V'])\n",
    "    plot_dict[_class]['y_values'].append(testbed_stats[test][_class]['nn_fct'])\n",
    "\n",
    "fig = tpg.plot_val_scatter(plot_dict=plot_dict,xlabel='V', ylabel='99th Percentile FCT (us)', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# throughput\n",
    "plot_dict = {_class: {'x_values': [], 'y_values': []} for _class in classes}\n",
    "\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    plot_dict[_class]['x_values'].append(testbed_stats[test][_class]['V'])\n",
    "    plot_dict[_class]['y_values'].append(testbed_stats[test][_class]['throughput'])\n",
    "\n",
    "fig = tpg.plot_val_scatter(plot_dict=plot_dict,xlabel='V', ylabel='Throughput (B/s)', show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# queue length\n",
    "plot_dict = {}\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    load = testbed_stats[test][_class]['load_frac']\n",
    "    try:\n",
    "        plot_dict[load][_class]['x_values'] = None\n",
    "        plot_dict[load][_class]['y_values'] = None\n",
    "    except KeyError:\n",
    "        # not yet added this load\n",
    "        try:\n",
    "            plot_dict[load][_class] = {}\n",
    "            plot_dict[load][_class]['x_values'] = None\n",
    "            plot_dict[load][_class]['y_values'] = None\n",
    "        except KeyError:\n",
    "            plot_dict[load] = {}\n",
    "            plot_dict[load][_class] = {}\n",
    "            plot_dict[load][_class]['x_values'] = None\n",
    "            plot_dict[load][_class]['y_values'] = None\n",
    "\n",
    "src = 'server_2'\n",
    "dst='server_10'\n",
    "for test in testbed_stats.keys():\n",
    "    _class = list(testbed_stats[test].keys())[0]\n",
    "    load = testbed_stats[test][_class]['load_frac']\n",
    "    plot_dict[load][_class]['x_values'] = testbed_stats[test][_class]['q_dict'][src][dst]['times'] \n",
    "    plot_dict[load][_class]['y_values'] = testbed_stats[test][_class]['q_dict'][src][dst]['queue_lengths']\n",
    "    \n",
    "for load in plot_dict.keys():\n",
    "    tpg.plot_val_line(plot_dict=plot_dict[load],xlabel='Time (us)', ylabel='{}-{} Queue Length (Bytes)'.format(src,dst), show_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634720.852958146\n",
      "12000\n",
      "4347\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import trafpy\n",
    "from trafpy.manager import EnvAnalyser\n",
    "\n",
    "analyser = EnvAnalyser(env=envs[-1])\n",
    "\n",
    "analyser.compute_flow_summary()\n",
    "print(analyser.measurement_duration)\n",
    "print(analyser.num_arrived_flows)\n",
    "print(analyser.num_completed_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_scheduler",
   "language": "python",
   "name": "deep_scheduler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
