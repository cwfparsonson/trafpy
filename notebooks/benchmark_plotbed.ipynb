{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Benchmark Testbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.1_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.1_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.1_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.1_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.2_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.2_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.2_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.2_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.3_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.3_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.3_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.3_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.4_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.4_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.4_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.4_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.5_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.5_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.5_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.5_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.6_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.6_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.6_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.6_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.7_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.7_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.7_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.7_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.8_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.8_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.8_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.8_repeat_0_scheduler_SRPT', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.9_repeat_0_scheduler_FF', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.9_repeat_0_scheduler_FS', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.9_repeat_0_scheduler_Rand', '/scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.9_repeat_0_scheduler_SRPT']\n",
      "No simulation.obj in /scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.9_repeat_0_scheduler_Rand\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import trafpy\n",
    "import trafpy.generator as tpg\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# DATA_NAME = 'social_media_cloud_k_4_L_2_n_4_chancap500_numchans1_mldat2e6_bidirectional'\n",
    "DATA_NAME = 'university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional'\n",
    "\n",
    "\n",
    "# path_to_benchmark_data = '/scratch/datasets/trafpy/management/flowcentric/{}_testbed_data_v3.obj'.format(DATA_NAME)\n",
    "path_to_testbed_data = '/scratch/datasets/trafpy/management/flowcentric/{}_testbed_data_v2'.format(DATA_NAME)\n",
    "\n",
    "if os.path.isdir(path_to_testbed_data):\n",
    "    # data split into separate files in a directory\n",
    "    separate_files = True\n",
    "    # load paths to testbed data dirs\n",
    "    testbed_data_list = sorted(glob.glob(path_to_testbed_data + '/*'))\n",
    "    print(testbed_data_list)\n",
    "    envs = []\n",
    "    for testbed_path in testbed_data_list:\n",
    "        try:\n",
    "            filehandler = open(testbed_path+'/simulation.obj', 'rb')\n",
    "            envs.append(pickle.load(filehandler))\n",
    "        except FileNotFoundError:\n",
    "            print('No simulation.obj in {}'.format(testbed_path))\n",
    "        \n",
    "else:\n",
    "    # all data stored in single file\n",
    "    separate_files = False\n",
    "    # load raw testbed data\n",
    "    filehandler = open(path_to_benchmark_data, 'rb')\n",
    "    testbed_data = pickle.load(filehandler)\n",
    "    print(testbed_data.keys())\n",
    "    # unpack env dicts into list of env objects\n",
    "    envs = testbed_data['envs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF...\n",
      "Overwriting /scratch/datasets/trafpy/management/flowcentric/university_k_4_L_2_n_4_chancap3125_numchans1_mldat2e6_bidirectional_testbed_data_v2/benchmark_university_load_0.1_repeat_0_scheduler_FF/env_analyser_database...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF in 191.29645800590515 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF in 100.42183828353882 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF in 26.871174812316895 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF in 12.674170732498169 s.\n",
      "Computed metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FF in 372.71364665031433 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_FF'\n",
      "Measurement duration: 3937477.46723991 (Start time : 437497.49635999 μs | End time: 4374974.9635999 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 427107\n",
      "Total info arrived: 9852421366.0 B\n",
      "Total info transported: 9851878064.0 B\n",
      "Load (abs): 2502.216570881444 B/μs\n",
      "Load (frac): 0.10008866283525776 fraction of network capacity requested.\n",
      "Throughput (abs): 2502.0785886315084 B/μs\n",
      "Throughput (frac): 0.9999448559922666 fraction of arrived info successfully transported.\n",
      "T-Score: 1.4905652048334055\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 427107\n",
      "Time first flow arrived: 437498.0507996343 μs\n",
      "Time last flow arrived: 4374974.1008127285 μs\n",
      "Total number of flows that were completed: 427104\n",
      "Total number of flows that were left in queue at end of measurement period: 3\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 3\n",
      "Fraction of arrived flows dropped: 7.024001011456145e-06\n",
      "Mean flow completion time (FCT): 46.366865428094194 μs\n",
      "99th percentile FCT: 428.50974735056514 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS in 188.5433864593506 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS in 93.51004576683044 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS in 24.985878467559814 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS in 11.790731191635132 s.\n",
      "Computed metrics for env benchmark_university_load_0.1_repeat_0_scheduler_FS in 358.65221428871155 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_FS'\n",
      "Measurement duration: 3937477.46723991 (Start time : 437497.49635999 μs | End time: 4374974.9635999 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 427107\n",
      "Total info arrived: 9852421366.0 B\n",
      "Total info transported: 9851878064.0 B\n",
      "Load (abs): 2502.216570881444 B/μs\n",
      "Load (frac): 0.10008866283525776 fraction of network capacity requested.\n",
      "Throughput (abs): 2502.0785886315084 B/μs\n",
      "Throughput (frac): 0.9999448559922666 fraction of arrived info successfully transported.\n",
      "T-Score: 1.5813241937820988\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 427107\n",
      "Time first flow arrived: 437498.0507996343 μs\n",
      "Time last flow arrived: 4374974.1008127285 μs\n",
      "Total number of flows that were completed: 427104\n",
      "Total number of flows that were left in queue at end of measurement period: 3\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 3\n",
      "Fraction of arrived flows dropped: 7.024001011456145e-06\n",
      "Mean flow completion time (FCT): 38.66452595105817 μs\n",
      "99th percentile FCT: 294.418745525659 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand in 187.05204057693481 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand in 97.93549180030823 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand in 25.517940044403076 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand in 13.71231722831726 s.\n",
      "Computed metrics for env benchmark_university_load_0.1_repeat_0_scheduler_Rand in 363.86667490005493 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_Rand'\n",
      "Measurement duration: 3937477.46723991 (Start time : 437497.49635999 μs | End time: 4374974.9635999 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 427107\n",
      "Total info arrived: 9852421366.0 B\n",
      "Total info transported: 9851877994.0 B\n",
      "Load (abs): 2502.216570881444 B/μs\n",
      "Load (frac): 0.10008866283525776 fraction of network capacity requested.\n",
      "Throughput (abs): 2502.078570853629 B/μs\n",
      "Throughput (frac): 0.9999448488874141 fraction of arrived info successfully transported.\n",
      "T-Score: 1.4972811464386766\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 427107\n",
      "Time first flow arrived: 437498.0507996343 μs\n",
      "Time last flow arrived: 4374974.1008127285 μs\n",
      "Total number of flows that were completed: 427103\n",
      "Total number of flows that were left in queue at end of measurement period: 4\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 4\n",
      "Fraction of arrived flows dropped: 9.365334681941528e-06\n",
      "Mean flow completion time (FCT): 42.24982639012684 μs\n",
      "99th percentile FCT: 326.5488054173704 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT in 183.1985936164856 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT in 96.94472408294678 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT in 25.80237317085266 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed flow dropped metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT in 11.942517518997192 s.\n",
      "Computed metrics for env benchmark_university_load_0.1_repeat_0_scheduler_SRPT in 359.311039686203 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.1_repeat_0_scheduler_SRPT'\n",
      "Measurement duration: 3937477.46723991 (Start time : 437497.49635999 μs | End time: 4374974.9635999 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 427107\n",
      "Total info arrived: 9852421366.0 B\n",
      "Total info transported: 9851878064.0 B\n",
      "Load (abs): 2502.216570881444 B/μs\n",
      "Load (frac): 0.10008866283525776 fraction of network capacity requested.\n",
      "Throughput (abs): 2502.0785886315084 B/μs\n",
      "Throughput (frac): 0.9999448559922666 fraction of arrived info successfully transported.\n",
      "T-Score: 1.6036924349893835\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 427107\n",
      "Time first flow arrived: 437498.0507996343 μs\n",
      "Time last flow arrived: 4374974.1008127285 μs\n",
      "Total number of flows that were completed: 427104\n",
      "Total number of flows that were left in queue at end of measurement period: 3\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 3\n",
      "Fraction of arrived flows dropped: 7.024001011456145e-06\n",
      "Mean flow completion time (FCT): 37.26533512165828 μs\n",
      "99th percentile FCT: 265.27377301436576 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF in 189.0930962562561 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF in 94.00942277908325 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF in 25.585185766220093 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF in 11.704630136489868 s.\n",
      "Computed metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FF in 361.77936363220215 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_FF'\n",
      "Measurement duration: 1948169.3633999985 (Start time : 216463.26259999984 μs | End time: 2164632.6259999983 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 426912\n",
      "Total info arrived: 9697560567.0 B\n",
      "Total info transported: 9696940000.0 B\n",
      "Load (abs): 4977.7810642066315 B/μs\n",
      "Load (frac): 0.19911124256826526 fraction of network capacity requested.\n",
      "Throughput (abs): 4977.462525679305 B/μs\n",
      "Throughput (frac): 0.9999360079273841 fraction of arrived info successfully transported.\n",
      "T-Score: 1.336488707266213\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 426912\n",
      "Time first flow arrived: 216466.23856552376 μs\n",
      "Time last flow arrived: 2164610.9436765453 μs\n",
      "Total number of flows that were completed: 426907\n",
      "Total number of flows that were left in queue at end of measurement period: 5\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 5\n",
      "Fraction of arrived flows dropped: 1.1712015591035155e-05\n",
      "Mean flow completion time (FCT): 68.27701314264667 μs\n",
      "99th percentile FCT: 869.0177545245745 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS in 193.06553554534912 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS in 99.53025555610657 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS in 25.75423288345337 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS in 10.802620887756348 s.\n",
      "Computed metrics for env benchmark_university_load_0.2_repeat_0_scheduler_FS in 370.4058344364166 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_FS'\n",
      "Measurement duration: 1948169.3633999985 (Start time : 216463.26259999984 μs | End time: 2164632.6259999983 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 426912\n",
      "Total info arrived: 9697560567.0 B\n",
      "Total info transported: 9696940000.0 B\n",
      "Load (abs): 4977.7810642066315 B/μs\n",
      "Load (frac): 0.19911124256826526 fraction of network capacity requested.\n",
      "Throughput (abs): 4977.462525679305 B/μs\n",
      "Throughput (frac): 0.9999360079273841 fraction of arrived info successfully transported.\n",
      "T-Score: 1.4820838274615953\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 426912\n",
      "Time first flow arrived: 216466.23856552376 μs\n",
      "Time last flow arrived: 2164610.9436765453 μs\n",
      "Total number of flows that were completed: 426907\n",
      "Total number of flows that were left in queue at end of measurement period: 5\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 5\n",
      "Fraction of arrived flows dropped: 1.1712015591035155e-05\n",
      "Mean flow completion time (FCT): 43.29932479366201 μs\n",
      "99th percentile FCT: 360.29440828515936 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand...\n",
      "Computed flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand in 189.18538355827332 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand in 95.34396648406982 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand in 25.252398014068604 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand in 12.323506832122803 s.\n",
      "Computed metrics for env benchmark_university_load_0.2_repeat_0_scheduler_Rand in 363.30437564849854 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_Rand'\n",
      "Measurement duration: 1948169.3633999985 (Start time : 216463.26259999984 μs | End time: 2164632.6259999983 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 426912\n",
      "Total info arrived: 9697560567.0 B\n",
      "Total info transported: 9696939773.0 B\n",
      "Load (abs): 4977.7810642066315 B/μs\n",
      "Load (frac): 0.19911124256826526 fraction of network capacity requested.\n",
      "Throughput (abs): 4977.462409159662 B/μs\n",
      "Throughput (frac): 0.9999359845194354 fraction of arrived info successfully transported.\n",
      "T-Score: 1.3740846380692702\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 426912\n",
      "Time first flow arrived: 216466.23856552376 μs\n",
      "Time last flow arrived: 2164610.9436765453 μs\n",
      "Total number of flows that were completed: 426906\n",
      "Total number of flows that were left in queue at end of measurement period: 6\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 6\n",
      "Fraction of arrived flows dropped: 1.4054418709242186e-05\n",
      "Mean flow completion time (FCT): 52.3862111451688 μs\n",
      "99th percentile FCT: 434.89381983420253 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed flow arrival metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT in 192.68719029426575 s.\n",
      "Computing flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT...\n",
      "Computed flow completion metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT in 94.58940362930298 s.\n",
      "Computing flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT...\n",
      "Computed flow queued metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT in 25.4905424118042 s.\n",
      "Computing flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT...\n",
      "Computed flow dropped metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT in 13.594382047653198 s.\n",
      "Computed metrics for env benchmark_university_load_0.2_repeat_0_scheduler_SRPT in 366.73781991004944 s.\n",
      "\n",
      "-=-=-=-=-=-=--= Summary -=-=-=-=-=-=-=-\n",
      "\n",
      " ~* General Information *~\n",
      "Simulation name: 'benchmark_university_load_0.2_repeat_0_scheduler_SRPT'\n",
      "Measurement duration: 1948169.3633999985 (Start time : 216463.26259999984 μs | End time: 2164632.6259999983 μs)\n",
      "Total number of generated demands (jobs or flows) passed to env: 474449\n",
      "Total number of these demands which arrived during measurement period: 426912\n",
      "Total info arrived: 9697560567.0 B\n",
      "Total info transported: 9696940000.0 B\n",
      "Load (abs): 4977.7810642066315 B/μs\n",
      "Load (frac): 0.19911124256826526 fraction of network capacity requested.\n",
      "Throughput (abs): 4977.462525679305 B/μs\n",
      "Throughput (frac): 0.9999360079273841 fraction of arrived info successfully transported.\n",
      "T-Score: 1.5117827141727391\n",
      "\n",
      " ~* Flow Information *~\n",
      "Total number of generated flows passed to env (src != dst, dependency_type == 'data_dep'): 474449\n",
      "Total number of these flows which arrived during measurement period: 426912\n",
      "Time first flow arrived: 216466.23856552376 μs\n",
      "Time last flow arrived: 2164610.9436765453 μs\n",
      "Total number of flows that were completed: 426907\n",
      "Total number of flows that were left in queue at end of measurement period: 5\n",
      "Total number of flows that were dropped (dropped + left in queue at end of measurement period): 5\n",
      "Fraction of arrived flows dropped: 1.1712015591035155e-05\n",
      "Mean flow completion time (FCT): 39.726766836074056 μs\n",
      "99th percentile FCT: 284.9770993060153 μs\n",
      "\n",
      "Computing metrics for env benchmark_university_load_0.3_repeat_0_scheduler_FF...\n",
      "Computing flow arrival metrics for env benchmark_university_load_0.3_repeat_0_scheduler_FF...\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import trafpy\n",
    "from trafpy.manager import EnvAnalyser, EnvsPlotter\n",
    "\n",
    "# analyse\n",
    "analysers = [EnvAnalyser(env, time_units='\\u03BCs', info_units='B', subject_class_name=env.scheduler.scheduler_name) for env in envs]\n",
    "for analyser in analysers:\n",
    "    analyser.compute_metrics(measurement_start_time='auto',\n",
    "                             measurement_end_time='auto',\n",
    "                             env_analyser_database_path=path_to_testbed_data+'/'+analyser.env.sim_name,\n",
    "                             print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import trafpy\n",
    "from trafpy.manager import EnvAnalyser, EnvsPlotter\n",
    "    \n",
    "# plot\n",
    "plotter = EnvsPlotter(time_units='\\u03BCs', info_units='B')\n",
    "_ = plotter.display_t_score_table(*analysers, display_table=True)\n",
    "# _ = plotter.plot_t_score_scatter(*analysers, gridlines=True, figsize=(4, 3), legend_ncol=2)\n",
    "\n",
    "# COMMENT IF HAVEN'T TRACKED QUEUE EVOLUTION AND SCHEDULER DECISION COLOUR GRID\n",
    "# _ = plotter.plot_src_dst_queue_evolution_for_different_loads('server_2', 'server_10', 'queue_lengths_num_flows', *analysers)\n",
    "# _ = plotter.plot_src_dst_queue_evolution_for_different_loads('server_2', 'server_10', 'queue_lengths_info_units', *analysers)\n",
    "# _ = plotter.plot_demand_slot_colour_grid_for_different_schedulers(*analysers)\n",
    "\n",
    "# COMMENT IF WANT TO SAVE TIME\n",
    "_ = plotter.plot_link_utilisation_vs_time_for_different_loads(*analysers, mean_period=2500, figsize=(6, 2), legend_ncol=2, plot_legend=False) # mean_period=2500\n",
    "# _ = plotter.plot_link_concurrent_demands_vs_time_for_different_loads(*analysers, mean_period=500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_ = plotter.plot_demand_completion_time_vs_size_for_different_loads(*analysers, gridlines=True, figsize=(4, 3), legend_ncol=2)\n",
    "_ = plotter.plot_throughput_rate_vs_load(*analysers, plot_bar_charts=False, gridlines=True, figsize=(6, 2), legend_ncol=2)\n",
    "_ = plotter.plot_throughput_frac_vs_load(*analysers, plot_bar_charts=False, gridlines=True, figsize=(6, 2), legend_ncol=2)\n",
    "_ = plotter.plot_fcts_cdf_for_different_loads(*analysers, gridlines=True, figsize=(6, 2), legend_ncol=2)\n",
    "_ = plotter.plot_mean_fct_vs_load(*analysers, logscale=True, gridlines=True, cdf_figsize=(6, 2), scatter_figsize=(4,3), legend_ncol=2)\n",
    "_ = plotter.plot_99th_percentile_fct_vs_load(*analysers, logscale=True, gridlines=True, cdf_figsize=(6, 2), scatter_figsize=(4,3), legend_ncol=2)\n",
    "_ = plotter.plot_max_fct_vs_load(*analysers, gridlines=True, logscale=True, cdf_figsize=(6, 2), scatter_figsize=(4,3), legend_ncol=2)\n",
    "_ = plotter.plot_fraction_of_arrived_flows_dropped_vs_load(*analysers, logscale=True, gridlines=True, cdf_figsize=(6, 2), scatter_figsize=(4,3), legend_ncol=2)\n",
    "_ = plotter.plot_fraction_of_arrived_info_dropped_vs_load(*analysers, logscale=True, gridlines=True, cdf_figsize=(6, 2), scatter_figsize=(4,3), legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM RADAR PLOT(S)\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import trafpy.generator as tpg\n",
    "\n",
    "time_units = '\\u03BCs'\n",
    "info_units = 'B'\n",
    "\n",
    "plot_dict = {'Mean FCT ({})'.format(time_units): {'range': [0, 1], 'classes': {'class1': 0.2,\n",
    "                                                         'class2': 0.4}},\n",
    "             'p99 FCT ({})'.format(time_units): {'range': [0, 100], 'classes': {'class1': 60,\n",
    "                                                           'class2': 20}},\n",
    "             'Max FCT ({})'.format(time_units): {'range': [1, 5], 'classes': {'class1': 2,\n",
    "                                                         'class2': 5}},\n",
    "             'Throughput Rate ({}/{})'.format(info_units, time_units): {'range': [0, 10], 'classes': {'class1': 7,\n",
    "                                                          'class2': 3}},\n",
    "             'Frac Info Dropped': {'range': [0, 10], 'classes': {'class1': 7,\n",
    "                                                          'class2': 3}},\n",
    "             'Frac Flows Dropped': {'range': [10, 0], 'classes': {'class1': 1,\n",
    "                                                          'class2': 2}}\n",
    "            }\n",
    "\n",
    "_ = tpg.plot_radar(plot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT SCHEDULER SENSITIVITY TO LOAD\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import trafpy.generator as tpg\n",
    "\n",
    "from collections import defaultdict\n",
    "import sigfig\n",
    "\n",
    "\n",
    "def get_summary_dict(analysers, headers, time_units='', info_units=''):\n",
    "    summary_dict = {header: [] for header in headers}\n",
    "    for analyser in analysers:\n",
    "        # self._check_analyser_valid(analyser)\n",
    "        summary_dict['Load'].append(round(analyser.load_frac, 2))\n",
    "        summary_dict['Subject'].append(analyser.subject_class_name)\n",
    "        summary_dict['T-Score'].append(analyser.t_score)\n",
    "        summary_dict['Mean FCT ({})'.format(time_units)].append(round(analyser.mean_fct, 1))\n",
    "        summary_dict['p99 FCT ({})'.format(time_units)].append(round(analyser.nn_fct, 1))\n",
    "        summary_dict['Max FCT ({})'.format(time_units)].append(round(analyser.max_fct, 1))\n",
    "        summary_dict['Throughput Frac'].append(round(analyser.throughput_frac, 1))\n",
    "        summary_dict['Frac Flows Dropped'].append(sigfig.round(analyser.dropped_flow_frac, sigfigs=3))\n",
    "        summary_dict['Frac Info Dropped'].append(sigfig.round(analyser.dropped_info_frac, sigfigs=3))\n",
    "    return summary_dict\n",
    "\n",
    "\n",
    "\n",
    "time_units = '\\u03BCs'\n",
    "info_units = 'B'\n",
    "headers = ['Load',\n",
    "           'T-Score',\n",
    "           'Subject',\n",
    "           'Mean FCT ({})'.format(time_units),\n",
    "           'p99 FCT ({})'.format(time_units),\n",
    "           'Max FCT ({})'.format(time_units),\n",
    "           'Throughput Frac',\n",
    "           'Frac Info Dropped',\n",
    "           'Frac Flows Dropped']\n",
    "dont_plot_headers = ['Load', 'T-Score', 'Subject']\n",
    "plot_headers = [header for header in headers if header not in dont_plot_headers]\n",
    "# determine if higher is better for each header\n",
    "is_higher_better = {}\n",
    "for header in headers:\n",
    "    if header == 'T-Score' or header == 'Throughput Frac':\n",
    "        is_higher_better[header] = True\n",
    "    else:\n",
    "        is_higher_better[header] = False\n",
    "\n",
    "scheduler_to_analysers = {}\n",
    "for analyser in analysers:\n",
    "    if analyser.env.scheduler.scheduler_name not in scheduler_to_analysers:\n",
    "        scheduler_to_analysers[analyser.env.scheduler.scheduler_name] = [analyser]\n",
    "    else:\n",
    "        scheduler_to_analysers[analyser.env.scheduler.scheduler_name].append(analyser)\n",
    "\n",
    "for scheduler_name in scheduler_to_analysers.keys():\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "    plot_dict = nested_dict()\n",
    "    \n",
    "    anys = scheduler_to_analysers[scheduler_name]\n",
    "    summary_dict = get_summary_dict(anys, headers, time_units=time_units, info_units=info_units)\n",
    "    \n",
    "    for header in plot_headers:\n",
    "        min_val, max_val = min(summary_dict[header]), max(summary_dict[header])\n",
    "        \n",
    "#         if is_higher_better[header]:\n",
    "#             # want higher (better) values on outer radar edge -> don't flip range\n",
    "#             _range = [0.9*min(summary_dict[header]), 1.1*max(summary_dict[header])]\n",
    "#         else:\n",
    "#             # want lower (better) values on outer radar edge -> flip range\n",
    "#             _range = [1.1*max(summary_dict[header]), 0.9*min(summary_dict[header])]\n",
    "            \n",
    "        diff = max(max_val - min_val, 1e-9)\n",
    "        min_val -= (0.1*diff)\n",
    "        max_val += (0.1*diff)\n",
    "        _range = [min_val, max_val]\n",
    "#         _range = [max(min_val, 1e-9), max(max_val, 1e-9)]\n",
    "        if not is_higher_better[header]:\n",
    "            # flip axis\n",
    "            _range = _range[::-1]\n",
    "\n",
    "        plot_dict[header]['range'] = _range\n",
    "        for i, load in enumerate(summary_dict['Load']):\n",
    "            plot_dict[header]['classes']['Load {}'.format(str(load))] = summary_dict[header][i]\n",
    "        \n",
    "    tpg.plot_radar(plot_dict, \n",
    "                   title=scheduler_name,\n",
    "                   fill=True,\n",
    "                   fill_alpha=0.05,\n",
    "                   figsize=(12.8, 9.6))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autoreload\n",
    "# import trafpy\n",
    "# import trafpy.generator as tpg\n",
    "# from trafpy.manager import RandomAgent, RWA, Demand, DCN, EnvAnalyser\n",
    "# import json\n",
    "\n",
    "# DATA_BAME = 'artificial_light_chancap10'\n",
    "# path_to_benchmark_data = os.path.dirname(trafpy.__file__)+'/../data/benchmark_data/{}_benchmark_data.json'.format(DATA_NAME)\n",
    "# benchmark_data = json.loads(tpg.load_data_from_json(path_to_benchmark_data))\n",
    "# benchmarks = list(benchmark_data.keys())\n",
    "\n",
    "# SLOT_SIZE = 1.0\n",
    "# PACKET_SIZE = 1\n",
    "# NUM_CHANNELS = 1\n",
    "# NUM_K_PATHS = 1\n",
    "# MAX_FLOWS = 10\n",
    "# MAX_TIME = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = tpg.gen_fat_tree(k=3, N=2, num_channels=1, server_to_rack_channel_capacity=10)\n",
    "# rwa = RWA(tpg.gen_channel_names(NUM_CHANNELS), NUM_K_PATHS)\n",
    "# scheduler = RandomAgent(network, rwa, slot_size=SLOT_SIZE, packet_size=PACKET_SIZE)\n",
    "\n",
    "# num_benchmark_tests = 0\n",
    "# for benchmark in benchmarks:\n",
    "#     for load in benchmark_data[benchmark]:\n",
    "#         for repeat in benchmark_data[benchmark][load]:\n",
    "#             num_benchmark_tests += 1\n",
    "\n",
    "# for benchmark in benchmarks:\n",
    "#     for load in list(benchmark_data[benchmark].keys()):\n",
    "#         for repeat in benchmark_data[benchmark][load]:\n",
    "#             if json.loads(load) == 0.1 and scheduler.scheduler_name == 'random':\n",
    "#                 demand_data = benchmark_data[benchmark][load][repeat]\n",
    "#                 demand = tpg.Demand(demand_data)\n",
    "#                 env = DCN(network, demand, scheduler, num_k_paths=NUM_K_PATHS, slot_size=SLOT_SIZE, max_flows=MAX_FLOWS, max_time=MAX_TIME)\n",
    "#                 print(env.slot_size)\n",
    "                \n",
    "#                 observation = env.reset()\n",
    "#                 scheduler.register_env(env)\n",
    "                \n",
    "#                 while True:\n",
    "#                     action = scheduler.get_action(observation)\n",
    "#                     observation, reward, done, info = env.step(action)\n",
    "                    \n",
    "#                     if done:\n",
    "#                         print('Completed')\n",
    "#                         analyser = EnvAnalyser(env)\n",
    "#                         analyser.compute_metrics(print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packet size = info\n",
    "# slot size = sec\n",
    "# min bandwidth in network = info per sec\n",
    "\n",
    "# assume that 1 packet size of info can be transferred per sub slot\n",
    "# info per sub slot = 1 packet = packet size\n",
    "# sub slot size = (info per sub slot / min bandwidth in network) * slot size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "if a is not None:\n",
    "    print('not none')\n",
    "else:\n",
    "    print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment_time = 1.001\n",
    "print(round(1-(increment_time-1),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_link_capacity = 500\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_scheduler",
   "language": "python",
   "name": "deep_scheduler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
