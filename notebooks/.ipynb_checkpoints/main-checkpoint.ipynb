{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TrafPy Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafpy.generator as tpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global Variables\n",
    "\n",
    "Set global vars. To change a global a global var, edit this cell and re-run the cell.\n",
    "\n",
    "- PATH: The path to the folder where you want to save and/or load data. \n",
    "- NUM_DEMANDS: Number of demands to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'data/interactive_test/'\n",
    "NUM_DEMANDS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Variables from 'Named' Distribution\n",
    "\n",
    "Generate a distribution of random variables using one of the following standard named distributions:\n",
    "\n",
    "- exponential\n",
    "- lognormal\n",
    "- weibull\n",
    "- pareto\n",
    "\n",
    "This might be e.g. interarrival times, sizes, number of nodes in a job, probability of job dependency/edge formation etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00d39aa064442aea3f2a158d6255029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatText(value=5.0, description='_alpha:', step=0.1), FloatText(value=0.5, description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_vars = tpg.gen_named_val_dist(dist='lognormal',\n",
    "                                   interactive_plot=True,\n",
    "                                   xlim=[1e1,1e6],\n",
    "                                   rand_var_name='Flow Size (Bytes)',\n",
    "                                   prob_rand_var_less_than=[300, 100000],\n",
    "                                   num_bins=20,\n",
    "                                   size=NUM_DEMANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "filename = 'random_variable'\n",
    "tpg.pickle_data(PATH+filename, rand_vars.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Variables from Arbitrary 'Multimodal' Distribution\n",
    "\n",
    "In previous cells we considered standard distributions (exponential, lognormal, weibull, pareto...). These are common distributions which occur in many different scenarios. However, sometimes in real scenarios distributions might not fall into these well-defined distribution categories. \n",
    "\n",
    "Multimodal distributions are distributions with >= 2 different modes. A multimodal distribution with 2 modes is a special case called a 'bimodal distribution', which is very common. \n",
    "\n",
    "The traffic toolbox allows you to generate arbitrary multimodal distributions. This is very powerful because with access to the above standard distributions and the arbitrary multimodal distribution generator, any distribution can be generated if you are able to shape it sufficiently.\n",
    "\n",
    "Generating multimodal distributions is a little more involved than generating the standard distributions was, but it can still be done in a matter of seconds using this notebook's visualisation tool. \n",
    "\n",
    "There are a few simple steps to generating an arbitrary multimodal distribution:\n",
    "\n",
    "1. Decide the number of modes (i.e. peaks) and other distribution characteristics\n",
    "2. Shape each mode individually\n",
    "3. Combine all of modes together and add some 'background noise' to the distribution such that the modes are 'joined' together to form a single multimodal distribution (background noise can be set to 0 if desired)\n",
    "4. Use your multimodal distribution to generate demands\n",
    "5. Save the generated demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define distribution variables\n",
    "min_val=1\n",
    "max_val=10000\n",
    "num_modes=4\n",
    "xlim=[1e-2,1e8]\n",
    "rand_var_name='Flow Interarrival Time (us)'\n",
    "round_to_nearest=1\n",
    "num_decimal_places=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. shape each mode\n",
    "data_dict = tpg.gen_skew_dists(min_val=min_val,\n",
    "                               max_val=max_val,\n",
    "                               num_modes=num_modes,\n",
    "                               xlim=xlim,\n",
    "                               rand_var_name=rand_var_name,\n",
    "                               round_to_nearest=round_to_nearest,\n",
    "                               num_decimal_places=num_decimal_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. combine modes to form multimodal probability distribution\n",
    "multimodal_prob_dist = tpg.combine_multiple_mode_dists(data_dict,\n",
    "                                                       min_val=min_val,\n",
    "                                                       max_val=max_val,\n",
    "                                                       xlim=xlim,\n",
    "                                                       rand_var_name=rand_var_name,\n",
    "                                                       round_to_nearest=round_to_nearest,\n",
    "                                                       num_decimal_places=num_decimal_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. use dist to generate random variables\n",
    "rand_vars = tpg.gen_rand_vars_from_discretised_dist(unique_vars=list(multimodal_prob_dist.result.keys()),\n",
    "                                                    probabilities=list(multimodal_prob_dist.result.values()),\n",
    "                                                    num_demands=NUM_DEMANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. save\n",
    "filename = 'multimodal_random_variable'\n",
    "tpg.pickle_data(PATH+filename, rand_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Discrete Probability Distribution from Random Variables\n",
    "\n",
    "Previous cells generated random variable data. However, sometimes it might be desirable to have the probability distribution/probability mass function (PMF) of the generated data rather than all the original generated data. Using the PMF, anyone can sample randomly from the PMF to produce new data with similar characteristics to the original data which you generated.\n",
    "\n",
    "Run this cell to load your previously generated distribution data and convert it into a PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'multimodal_random_variable_v2'\n",
    "\n",
    "rand_vars = tpg.unpickle_data(PATH+filename)\n",
    "xk, pmf = tpg.gen_discrete_prob_dist(rand_vars, \n",
    "                                     round_to_nearest=None,\n",
    "                                     num_decimal_places=2)\n",
    "prob_dist = {var: prob for var,prob in zip(xk,pmf)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "filename = 'prob_dist'\n",
    "tpg.pickle_data(PATH+filename, prob_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Variables from Discrete Probability Distribution\n",
    "\n",
    "Load a previously saved distribution and sample from it to generate any number of random variable data points. This function/cell does not plot the distribution, which avoids long delay times when trying to generate very large amounts of data.\n",
    "\n",
    "E.g. to generate 1,000,000 demands, would first shape the distribution visually with above cells for e.g. 10,000 demands, then save the discretised distribution, then in the below cell set num_demands in func below to 1,000,000 and run the cell to generate 1,000,000 demands from the previously shaped distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'prob_dist_v2'\n",
    "\n",
    "prob_dist = tpg.unpickle_data(PATH+filename)\n",
    "rand_vars = tpg.gen_rand_vars_from_discretised_dist(unique_vars=list(prob_dist.keys()),\n",
    "                                                    probabilities=list(prob_dist.values()),\n",
    "                                                    num_demands=NUM_DEMANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "filename = 'random_variables_from_prob_dist'\n",
    "tpg.pickle_data(PATH+filename, rand_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Source-Destination Node Distribution\n",
    "\n",
    "Generate a probability matrix describing the probability distribution of each source-node pair in a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINTS = ['ep_'+str(i) for i in range(5)] # define network endpoints\n",
    "\n",
    "\n",
    "# comment out all except one below\n",
    "\n",
    "# node_dist, _ = tpg.gen_uniform_node_dist(eps=ENDPOINTS,\n",
    "#                                          show_fig=True,\n",
    "#                                          print_data=True)\n",
    "\n",
    "node_dist, _ = tpg.gen_multimodal_node_dist(eps=ENDPOINTS,\n",
    "                                            skewed_nodes=[],\n",
    "                                            skewed_node_probs=[],\n",
    "                                            num_skewed_nodes=None,\n",
    "                                            show_fig=True,\n",
    "                                            print_data=True)\n",
    "\n",
    "# node_dist, _ = tpg.gen_multimodal_node_pair_dist(eps=ENDPOINTS,\n",
    "#                                                  skewed_pairs=[],\n",
    "#                                                  skewed_pair_probs=[],\n",
    "#                                                  num_skewed_pairs=None,\n",
    "#                                                  show_fig=True,\n",
    "#                                                  print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "filename = 'node_dist'\n",
    "tpg.pickle_data(PATH+filename, node_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Node Distribution to Generate Source-Destination Node Demands\n",
    "\n",
    "Sample from a previously generated source-destination probability matrix to generate source-destination node pair demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'node_dist'\n",
    "\n",
    "node_dist = tpg.unpickle_data(PATH+filename)\n",
    "node_demands = tpg.gen_node_demands(eps=ENDPOINTS,\n",
    "                                    node_dist=node_dist,\n",
    "                                    num_demands=NUM_DEMANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "filename = 'node_demands'\n",
    "tpg.pickle_data(PATH+filename, node_demands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Previously Generated Distributions to Create Single 'Demand Data' Dictionary\n",
    "\n",
    "Rather than having distributions spread across individual pickles or csvs, combine them into a demand_data dictionary. Can do this for 1) flow-centric demand data and 2) job-centric demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow-centric demand data\n",
    "flow_size_dist = tpg.unpickle_data(PATH+'flow_size_dist')\n",
    "interarrival_time_dist = tpg.unpickle_data(PATH+'interarrival_time_dist')\n",
    "node_dist = tpg.unpickle_data(PATH+'node_dist')\n",
    "\n",
    "flow_centric_demand_data = tpg.create_demand_data(num_demands=NUM_DEMANDS,\n",
    "                                                  eps=ENDPOINTS,\n",
    "                                                  node_dist=node_dist,\n",
    "                                                  flow_size_dist=flow_size_dist,\n",
    "                                                  interarrival_time_dist=interarrival_time_dist,\n",
    "                                                  print_data=True)\n",
    "print('Flow data:\\n{}'.format(flow_centric_demand_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job-centric demand data\n",
    "flow_size_dist = tpg.unpickle_data(PATH+'flow_size_dist')\n",
    "interarrival_time_dist = tpg.unpickle_data(PATH+'interarrival_time_dist')\n",
    "node_dist = tpg.unpickle_data(PATH+'node_dist')\n",
    "num_ops_dist = tpg.unpickle_data(PATH+'num_ops_dist')\n",
    "\n",
    "job_centric_demand_data = tpg.create_demand_data(num_demands=config.NUM_DEMANDS,\n",
    "                                                 eps=ENDPOINTS,\n",
    "                                                 node_dist=node_dist,\n",
    "                                                 flow_size_dist=flow_size_dist,\n",
    "                                                 interarrival_time_dist=interarrival_time_dist,\n",
    "                                                 num_ops_dist=num_ops_dist,\n",
    "                                                 c=1.5,\n",
    "                                                 use_multiprocessing=False,\n",
    "                                                 print_data=True)\n",
    "print('Job data:\\n{}'.format(job_centric_demand_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Distribution(s) in Set(s)/Loop(s)\n",
    "\n",
    "*(This is effectively an extension of the above interactive toolbox)*\n",
    "\n",
    "Sometimes, you may wish to generate e.g. 10 different sets of 10,000 demands, each with a different distribution. Doing this is easy, but does require a couple of lines of programming. To save time in generating large numbers of demands, no interactive visualisation is done here. Instead, you should use the above cells to shape your distributions, note down the parameters you decided on, and then enter your desired parameters in the code below. The code should then use your distribution characteristics to generate multiple sets of demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafpy.generator as tpg\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# set vars\n",
    "path = r'data/interactive_test/sets/'\n",
    "endpoints = ['ep_'+str(i) for i in range(5)]\n",
    "num_sets = 10 # init number of sets you want to generate\n",
    "num_demands = 10 # init number of demands you want to generate for each set\n",
    "\n",
    "\n",
    "# init demand object and dicts for saving\n",
    "dists = {'set': [],\n",
    "         'node_dist': [],\n",
    "         'flow_size_dist': [],\n",
    "         'interarrival_time_dist': []}\n",
    "data = {'set': [],\n",
    "        'source_nodes': [], \n",
    "        'destination_nodes': [],\n",
    "        'flow_sizes': [], \n",
    "        'interarrival_times': []}\n",
    "\n",
    "# set any distributions you want to keep constant for all sets\n",
    "flow_size_dist = tpg.gen_named_val_dist(dist='weibull',\n",
    "                                        params={'_alpha': 1.4, '_lambda': 7000},\n",
    "                                        return_data=False,\n",
    "                                        round_to_nearest=100)\n",
    "interarrival_dist = tpg.gen_named_val_dist(dist='exponential',\n",
    "                                           params={'_beta': 1.0},\n",
    "                                           return_data=False,\n",
    "                                           round_to_nearest=0.01)\n",
    "\n",
    "# generate demands for each set\n",
    "started = time.time()\n",
    "for s in range(num_sets):\n",
    "    start = time.time()\n",
    "    \n",
    "    # define distributions for this set\n",
    "    node_dist = tpg.gen_multimodal_node_dist(eps=endpoints,\n",
    "                                             skewed_nodes=[],\n",
    "                                             skewed_node_probs=[],\n",
    "                                             num_skewed_nodes=int(len(endpoints)*0.05))\n",
    "    dists['set'].append(s+1)\n",
    "    dists['node_dist'].append(copy.deepcopy(node_dist))\n",
    "    dists['flow_size_dist'].append(copy.deepcopy(flow_size_dist))\n",
    "    dists['interarrival_time_dist'].append(copy.deepcopy(interarrival_dist))\n",
    "    \n",
    "    # sample variables from distributions for this set\n",
    "    sn,dn = tpg.gen_node_demands(eps=endpoints,\n",
    "                                 node_dist=node_dist, \n",
    "                                 num_demands=num_demands)\n",
    "    flow_sizes = tpg.gen_rand_vars_from_discretised_dist(unique_vars=list(flow_size_dist.keys()),\n",
    "                                                         probabilities=list(flow_size_dist.values()),\n",
    "                                                         num_demands=num_demands)\n",
    "    interarrival_times = tpg.gen_rand_vars_from_discretised_dist(unique_vars=list(interarrival_dist.keys()),\n",
    "                                                                 probabilities=list(interarrival_dist.values()),\n",
    "                                                                 num_demands=num_demands)\n",
    "    data['set'].append(s+1)\n",
    "    data['source_nodes'].append(copy.deepcopy(sn))\n",
    "    data['destination_nodes'].append(copy.deepcopy(dn))\n",
    "    data['flow_sizes'].append(copy.deepcopy(flow_sizes))\n",
    "    data['interarrival_times'].append(copy.deepcopy(interarrival_times))\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Generated {} demands for set {} of {} in {} seconds.'.format(num_demands,s+1,num_sets, end-start))\n",
    "    \n",
    "# save generated dists and data\n",
    "tpg.save_data_as_csv(path_to_save=path+'distributions',\n",
    "                     data=dists,\n",
    "                     overwrite=False,\n",
    "                     print_times=True)\n",
    "tpg.save_data_as_csv(path_to_save=path+'data',\n",
    "                     data=data,\n",
    "                     overwrite=False,\n",
    "                     print_times=True)\n",
    "ended=time.time()\n",
    "print('Generated {} sets of {} demands in {} seconds.'.format(num_sets,num_demands,ended-started))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE OF HOW TO MAKE A UNIFORM DIST\n",
    "# flow_size_dist = tpg.gen_uniform_val_dist(min_flow_size,\n",
    "#                                           max_flow_size,\n",
    "#                                           round_to_nearest=1,\n",
    "#                                           path_to_save=path,\n",
    "#                                           filename='flow_size_dist_{}'.format(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_scheduler",
   "language": "python",
   "name": "deep_scheduler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
