{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import trafpy.generator as tpg\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = tpg.gen_uniform_node_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=True)\n",
    "_ = tpg.gen_uniform_multinomial_exp_node_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=True)\n",
    "_ = tpg.gen_multimodal_node_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=True)\n",
    "_ = tpg.gen_multimodal_node_pair_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tpg.gen_uniform_val_dist(min_val=1,\n",
    "                            max_val=100,\n",
    "                            show_fig=True,\n",
    "                            print_data=False)\n",
    "\n",
    "_ = tpg.gen_multimodal_val_dist(min_val=10,\n",
    "                               max_val=7000,\n",
    "                               locations=[20,4000],\n",
    "                               skews=[6,-1],\n",
    "                               scales=[150,1500],\n",
    "                               num_skew_samples=[10000,650],\n",
    "                               bg_factor=0.05,\n",
    "                               show_fig=True,\n",
    "                               print_data=False,\n",
    "                               logscale=True,\n",
    "                               xlim=[10,10000],\n",
    "                               num_bins=18)\n",
    "\n",
    "_ = tpg.gen_named_val_dist(dist='weibull',\n",
    "                          params={'_alpha': 1.4, '_lambda': 7000},\n",
    "                          show_fig=True,\n",
    "                          print_data=False,\n",
    "                          logscale=True,\n",
    "                          xlim=[1e2,1e11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Job-Centric Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_dist = tpg.gen_uniform_node_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=False)\n",
    "\n",
    "flow_size_dist = tpg.gen_multimodal_val_dist(config.MIN_FLOW_SIZE,\n",
    "                                            config.MAX_FLOW_SIZE,\n",
    "                                            locations=[50],\n",
    "                                            skews=[0],\n",
    "                                            scales=[10],\n",
    "                                            num_skew_samples=[10000],\n",
    "                                            bg_factor=0,\n",
    "                                            round_to_nearest=1,\n",
    "                                            show_fig=True,\n",
    "                                            num_bins=34,\n",
    "                                            print_data=False)\n",
    "\n",
    "interarrival_time_dist = tpg.gen_multimodal_val_dist(config.MIN_INTERARRIVAL,\n",
    "                                                    config.MAX_INTERARRIVAL,\n",
    "                                                    locations=[1, 1, 3000, 1, 1800000, 10000000],\n",
    "                                                    skews=[0, 100, -10, 10, 50, 6],\n",
    "                                                    scales=[0.1, 62, 2000, 7500, 3500000, 20000000],\n",
    "                                                    num_skew_samples=[800, 1000, 2000, 4000, 4000, 3000],\n",
    "                                                    bg_factor=0.025,\n",
    "                                                    round_to_nearest=1,\n",
    "                                                    show_fig=True,\n",
    "                                                    print_data=False)\n",
    "\n",
    "num_ops_dist = tpg.gen_multimodal_val_dist(config.MIN_NUM_OPS,\n",
    "                                          config.MAX_NUM_OPS,\n",
    "                                          locations=[100],\n",
    "                                          skews=[0.05],\n",
    "                                          scales=[50],\n",
    "                                          num_skew_samples=[10000],\n",
    "                                          bg_factor=0.05,\n",
    "                                          round_to_nearest=1,\n",
    "                                          show_fig=True,\n",
    "                                          print_data=False)\n",
    "\n",
    "\n",
    "job_centric_demand_data = tpg.create_demand_data(num_demands=config.NUM_DEMANDS,\n",
    "                                                eps=config.ENDPOINT_LABELS,\n",
    "                                                node_dist=node_dist,\n",
    "                                                flow_size_dist=flow_size_dist,\n",
    "                                                interarrival_time_dist=interarrival_time_dist,\n",
    "                                                num_ops_dist=num_ops_dist,\n",
    "                                                c=config.C,\n",
    "                                                use_multiprocessing=False,\n",
    "                                                print_data=True)\n",
    "print('Job data:\\n{}'.format(job_centric_demand_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Flow-Centric Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dist = tpg.gen_uniform_node_dist(config.ENDPOINT_LABELS, show_fig=True, print_data=False)\n",
    "\n",
    "flow_size_dist = tpg.gen_named_val_dist(dist='weibull',\n",
    "                                       params={'_alpha': 1.4, '_lambda': 7000},\n",
    "                                       show_fig=True,\n",
    "                                       print_data=False,\n",
    "                                       logscale=True,\n",
    "                                       round_to_nearest=1,\n",
    "                                       xlim=[1e2,1e12])\n",
    "\n",
    "interarrival_time_dist = tpg.gen_named_val_dist(dist='lognormal',\n",
    "                                               params={'_mu': 7.4, '_sigma': 2},\n",
    "                                               show_fig=True,\n",
    "                                               print_data=False,\n",
    "                                               logscale=True,\n",
    "                                               xlim=[1e1,1e6])\n",
    "\n",
    "\n",
    "flow_centric_demand_data = tpg.create_demand_data(num_demands=config.NUM_DEMANDS,\n",
    "                                                 eps=config.ENDPOINT_LABELS,\n",
    "                                                 node_dist=node_dist,\n",
    "                                                 flow_size_dist=flow_size_dist,\n",
    "                                                 interarrival_time_dist=interarrival_time_dist,\n",
    "                                                 print_data=True)\n",
    "print('Flow data:\\n{}'.format(flow_centric_demand_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organise into Slots Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DO THIS INTERNALLY IN DEMAND OBJECT WHEN PASS DEMAND INTO ENV\n",
    "\n",
    "# slot_size = 100000\n",
    "\n",
    "# job_centric_slot_dict = tpg.construct_demand_slots_dict(demand_data=job_centric_demand_data,\n",
    "#                                                        slot_size=slot_size)\n",
    "# # print('\\n\\nJob slot dict:\\n{}'.format(job_centric_slot_dict))\n",
    "\n",
    "\n",
    "# flow_centric_slot_dict = tpg.construct_demand_slots_dict(demand_data=flow_centric_demand_data,\n",
    "#                                                         slot_size=slot_size)\n",
    "# # print('\\n\\nFlow slot dict:\\n{}'.format(flow_centric_slot_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpg.pickle_data(data=flow_centric_demand_data,\n",
    "               path_to_save='data/flow_centric_demand_data.pickle',\n",
    "               overwrite=True,\n",
    "               zip_data=True)\n",
    "\n",
    "tpg.pickle_data(path_to_save='data/job_centric_demand_data.pickle',\n",
    "               data=job_centric_demand_data,\n",
    "               overwrite=True,\n",
    "               zip_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_centric_demand_data = tpg.unpickle_data(path_to_load='data/flow_centric_demand_data.pickle',\n",
    "                                             zip_data=True)\n",
    "job_centric_demand_data = tpg.unpickle_data(path_to_load='data/job_centric_demand_data.pickle',\n",
    "                                             zip_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Demand Object & Running Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand config file imported.\n"
     ]
    }
   ],
   "source": [
    "import trafpy.generator as tpg\n",
    "from trafpy.manager import Demand, RWA, SRPT, DCN\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data from data/flow_centric_demand_data.pickle: 0.0024089813232421875 s\n"
     ]
    }
   ],
   "source": [
    "# load demand data\n",
    "demand_data = tpg.unpickle_data(path_to_load='data/flow_centric_demand_data.pickle',\n",
    "                                zip_data=True)\n",
    "\n",
    "# init manager\n",
    "network = tpg.gen_simple_graph(ep_label=config.ENDPOINT_LABEL,num_channels=config.NUM_CHANNELS)\n",
    "demand = Demand(demand_data=demand_data)\n",
    "rwa = RWA(tpg.gen_channel_names(config.NUM_CHANNELS), config.NUM_K_PATHS)\n",
    "scheduler = SRPT(network, rwa, slot_size=config.SLOT_SIZE)\n",
    "env = DCN(network, demand, scheduler, slot_size=config.SLOT_SIZE, max_flows=config.MAX_FLOWS, max_time=config.MAX_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1/1\n",
      "Time: 10000.0\n",
      "Action:\n",
      "{'chosen_flows': [{'flow_id': 'flow_1', 'size': 6672.0, 'src': 'server_0', 'dst': 'server_3', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_0', 'server_1', 'server_3'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000.]), 'time_arrived': 4535.227460107683, 'time_completed': None, 'k_shortest_paths': [['server_0', 'server_1', 'server_3']]}, {'flow_id': 'flow_2', 'size': 4463.0, 'src': 'server_3', 'dst': 'server_4', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_3', 'server_4'], 'channel': 'channel_1', 'packets': array([3000., 3000.]), 'time_arrived': 5873.637473558241, 'time_completed': None, 'k_shortest_paths': [['server_3', 'server_4']]}]}\n",
      "Time: 20000.0\n",
      "Action:\n",
      "{'chosen_flows': [{'flow_id': 'flow_0', 'size': 12169.0, 'src': 'server_3', 'dst': 'server_1', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_3', 'server_1'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000., 3000., 3000.]), 'time_arrived': 0.0, 'time_completed': None, 'k_shortest_paths': [['server_3', 'server_1']]}, {'flow_id': 'flow_3', 'size': 4181.0, 'src': 'server_3', 'dst': 'server_4', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_3', 'server_4'], 'channel': 'channel_1', 'packets': array([3000., 3000.]), 'time_arrived': 5955.827821131925, 'time_completed': None, 'k_shortest_paths': [['server_3', 'server_4']]}]}\n",
      "Time: 30000.0\n",
      "Action:\n",
      "{'chosen_flows': [{'flow_id': 'flow_4', 'size': 12528.0, 'src': 'server_3', 'dst': 'server_4', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_3', 'server_4'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000., 3000., 3000.]), 'time_arrived': 6594.088798257897, 'time_completed': None, 'k_shortest_paths': [['server_3', 'server_4']]}]}\n",
      "Time: 40000.0\n",
      "Action:\n",
      "{'chosen_flows': [{'flow_id': 'flow_6', 'size': 8812.0, 'src': 'server_2', 'dst': 'server_3', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_2', 'server_1', 'server_3'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000.]), 'time_arrived': 38356.3377622449, 'time_completed': None, 'k_shortest_paths': [['server_2', 'server_1', 'server_3']]}, {'flow_id': 'flow_5', 'size': 11867.0, 'src': 'server_2', 'dst': 'server_4', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_2', 'server_4'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000., 3000.]), 'time_arrived': 37901.332797137205, 'time_completed': None, 'k_shortest_paths': [['server_2', 'server_4']]}]}\n",
      "Time: 50000.0\n",
      "Action:\n",
      "{'chosen_flows': [{'flow_id': 'flow_7', 'size': 5752.0, 'src': 'server_2', 'dst': 'server_3', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_2', 'server_1', 'server_3'], 'channel': 'channel_1', 'packets': array([3000., 3000.]), 'time_arrived': 40122.54646128949, 'time_completed': None, 'k_shortest_paths': [['server_2', 'server_1', 'server_3']]}, {'flow_id': 'flow_8', 'size': 4045.0, 'src': 'server_2', 'dst': 'server_4', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_2', 'server_4'], 'channel': 'channel_1', 'packets': array([3000., 3000.]), 'time_arrived': 40160.35192510108, 'time_completed': None, 'k_shortest_paths': [['server_2', 'server_4']]}, {'flow_id': 'flow_9', 'size': 6546.0, 'src': 'server_4', 'dst': 'server_3', 'establish': 1, 'parent_deps': None, 'completed_parent_deps': [], 'child_deps': None, 'parent_op_run_time': None, 'time_parent_op_started': None, 'parent_op': None, 'dependency_type': None, 'child_op': None, 'can_schedule': 1, 'job_id': None, 'path': ['server_4', 'server_3'], 'channel': 'channel_1', 'packets': array([3000., 3000., 3000.]), 'time_arrived': 40867.341579283486, 'time_completed': None, 'k_shortest_paths': [['server_4', 'server_3']]}]}\n",
      "Episode finished.\n",
      "-=-=-=-=-=-=-= Scheduling Session Ended -=-=-=-=-=-=-=\n",
      "SUMMARY:\n",
      "~* General Info *~\n",
      "Total session duration: 50000.0 time units\n",
      "Total number of generated demands (jobs or flows): 10\n",
      "Total info arrived: 77035.0 info units\n",
      "Load: 1.88500149564538 info unit demands arrived per unit time (from first to last flow arriving)\n",
      "Total info transported: 77035.0 info units\n",
      "Throughput: 1.5407 info units transported per unit time\n",
      "\n",
      "~* Flow Info *~\n",
      "Total number generated flows (src!=dst,dependency_type=='data_dep'): 10\n",
      "Time first flow arrived: 0.0 time units\n",
      "Time last flow arrived: 40867.341579283486 time units\n",
      "Time first flow completed: 10000.0 time units\n",
      "Time last flow completed: 50000.0 time units\n",
      "Total number of demands that arrived and became flows: 10\n",
      "Total number of flows that were completed: 10\n",
      "Total number of dropped flows + flows in queues at end of session: 0\n",
      "Average FCT: 9963.330792188808 time units\n",
      "99th percentile FCT: 23099.379193585315 time units\n"
     ]
    }
   ],
   "source": [
    "# run simulation\n",
    "for episode in range(config.NUM_EPISODES):\n",
    "    print('\\nEpisode {}/{}'.format(episode+1,config.NUM_EPISODES))\n",
    "    observation = env.reset(config.LOAD_DEMANDS)\n",
    "    while True:\n",
    "        print('Time: {}'.format(env.curr_time))\n",
    "        action = scheduler.get_action(observation)\n",
    "        print('Action:\\n{}'.format(action))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print('Episode finished.')\n",
    "            env.get_scheduling_session_summary(print_summary=True)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
